{"projects": [{"name":"After ALife Ahead","slug":"afteralifeahead","headline":"Real-Time Responsive Mobile Augmented Reality","previewImg":"/assets/projects/afteralifeahead/phar1.png","aspectRatio":"3-4","priority":1,"coverVid":{"vid":"/assets/projects/afteralifeahead/phar.mp4","poster":"/assets/projects/afteralifeahead/pharVidcover.png"},"roles":["Augmented Reality Design + Development","Custom iOS+Android Application","Content Server System"],"tech":["iOS & Android App","Custom Beacon Location Tracking","Real-time AR Server"],"links":[{"address":"https://www.artsy.net/article/artsy-editorial-pierre-huyghes-latest-project-biotech-lab-scene-sci-fi-film","text":"Artsy"},{"address":"http://www.artnews.com/2017/06/26/constant-displacement-pierre-huyghe-on-his-work-at-skulptur-projekte-munster-2017/","text":"Art News"},{"address":"http://theartnewspaper.com/reports/pierre-huyghe-creates-sci-fi-landscape-in-m-nster/","text":"The Art Newspaper"}],"content":"\n<p class=\"italic justLeft\">\n    Pierre Huyghe - After ALife Ahead - 2017<br>\n    Ice rink concrete floor; Sand, clay, phreatic water; Bacteria, algea, bee, chimera peacock; Aquarium, black switchable glass, conus textile; Incubator, human cancer cells; Genetic algorithm; Augemented reality; Automated ceiling structure; Rain; Ammoniac; Logic game.\n</p>\n\n<p>\n    Luxloop was approached to work with artist Pierre Huyghe on After ALife Ahead, the time-based bio-technical system he created for Skulptur Projkete Munster, an arts event that occurs every 10 years in Munster, Germany.\n</p>\n\n<p>\n    Huyghe’s work often explores the complex interactions between interdependent lifeforms and systems, including living cell cultures, animals, unicellular organisms and technology. For After ALife Ahead, he was interested in adding Augmented Reality as a virtual living element to the system. Imagining virtual entities living and interacting within the space, Huyghe needed an app that would allow visitors to peek into the virtual realm at any given moment.\n</p>\n\n<img src=\"/assets/projects/afteralifeahead/phar360.png\" class=\"caption captionDark captionRight captionOut\" data-caption=\"The Ice Rink location before Huyghe's intervention\">\n\n<h1>Creating a Virtual Living System</h1>\n\n<p>\n  Any living system has a set of basic rules that interact to determine how organisms live, procreate and die. Luxloop worked with Huyghe to develop a living algorithm for the AR that responded to realtime on-site data from the rink such as the temperature, animal movement, and precipitation. The rule-set controlled the AR creatures’ movement, colonization, death rates, and birthrates, allowing the system to live autonomously and be influenced by conditions in the environment.\n</p>\n\n<img src=\"/assets/projects/afteralifeahead/phar4.png\" class=\"caption captionLight captionRight captionIn\" data-caption=\"Photo: Pierre Huyghe\">\n\n<h1>A Virtual World that Exists Without You</h1>\n\n<p>\n  We built a server-based system that allowed users’ devices to sync to this autonomous world so that even at capacity of 200+ viewers, all visitors would see the same augmented system and animations in real time, bringing to life the illusion that the AR app is a viewport into the augmented living world.\n</p>\n\n<h1>Markerless Tracking</h1>\n\n<p>\n    There were a number of factors both conceptually and logistically that made markerless tracking a requirement of the project. Conceptually it was very important to Huyghe to resit altering the space solely to facilitate the AR by adding distracting markers or additional trackable elements. Additionally, the natural materials used would erode and change over time, limiting our ability to use features of the space itself as a reliable tracking marker.\n</p>\n\n<p>\n    Traditional Augmented Reality systems are designed to track a small area such as a tabletop or room, or use visual markers to position virtual content in real space. Huyghe was interested in the Augmented reality inhabiting the entire space above his monumental work (roughly  130ft x 200ft), which stretched the limits of the existing AR tracking algorithms available to date. We developed a custom algorithm for moving the viewers virtual point of view within the site using their mobile device’s internal sensors and bluetooth beacons, allowing viewers to look into the system no matter their location in the space.\n</p>\n\n<img src=\"/assets/projects/afteralifeahead/phar1.png\" class=\"caption captionLight captionRight captionIn\" data-caption=\"Photo: Ola Rindal\">\n\n<h1>Tech for Me, Tech for You: The Designing Future Artists’ Pallette</h1>\n\n<p>    \n    Pierre Huyghe has a history of working with new technologies, but this was his first time exploring Augmented Reality. Especially working at this monumental scale, working with any new medium called for rapid iteration, experimentation, and adjustment. Furthermore, designs may look correct when simulated on a desktop editor, but feel completely different when viewed in context.\n</p>\n\n<p>\n    It was important for us to develop a workflow that would not hold back Huyghe’s process due to purely technical limitations, so we created a series of artist “palette” apps that allowed us to work with Huyghe to make tweaks to the system in real time. This helped tremendously with our ability to update iterations of the AR content for the exhibition, as well as to tweak our lighting and textures systems on site and create the feeling that the virtual elements were actually occupying the real space instead of digitally pasted on top of the viewers camera.\n</p>\n\n<img src=\"/assets/projects/afteralifeahead/pharOverview.gif\" class=\"caption captionDark captionRight captionOut\" data-caption=\"System Server View\">\n\n"},{"name":"AL LA DO","projectPageLine":"Interactive Fashion Video","headline":"Interactive Fashion Video for Gypsy Sport F/W 2016 Collection","slug":"allado","previewImg":"/assets/projects/gypsysport/cover.jpg","aspectRatio":"9-16","priority":5,"coverImg":"/assets/projects/gypsysport/cover.jpg","roles":["Content Production","Interactive Experience-Design"],"tech":["HTML5"],"team":[{"credit":"Directed by","people":["Greg Luna and Luxloop"]},{"credit":"Featuring","people":["Ty Wells","Clarys Biagi","Jessica Hiestand"]},{"credit":"Soundtrack by","people":["Jaden Smith featuring Willow Smith"]}],"links":[{"address":"https://i-d.vice.com/en_gb/article/exclusive-watch-gypsy-sports-interactive-new-film-with-music-by-jaden-and-willow-smith","text":"i-D"},{"address":"http://www.papermag.com/watch-gypsy-sports-ss16-campaign-video-with-new-music-from-jaden-and-w-1737358014.html","text":"Paper"},{"address":"http://www.nylon.com/articles/willow-jaden-smith-gypsy-sport","text":"Nylon"},{"address":"http://www.thefader.com/2016/04/19/jaden-willow-smith-soundtrack-gypsy-sport-video","text":"Fader"},{"address":"http://www.oystermag.com/watch-jaden-and-willow-smith-times-gypsy-sports-interactive-dance-video","text":"Oyster"}],"content":"\n\n<p class=\"noShowLarge\">\n  Please visit this page on your desktop to try <span class=\"bolder\">Al La Do</span>\n</p>\n\n<div id=\"frameSizer\" style=\"position:relative;width:100%;height:0;padding-top:55%;\" class=\"noShowTablet\">\n  <iframe id=\"vidFrame\" src=\"http://www.luxloop.com/demo/gs/gsembed.html\" style=\"border:none;position:absolute;top:0;left:0;bottom:0;right:0;width:100%;height:100%\"></iframe>\n</div>\n"},{"name":"Black Cloak","projectPageLine":"Immersive Video Environment","headline":"Immersive Video Environment for Pop-up Dinner by Michelin-Star Chef","slug":"blackcloak","coverImg":"/assets/projects/blackcloak/screen1Offset.png","previewImg":"/assets/projects/blackcloak/screen1Offset.png","aspectRatio":"3-4","priority":2,"roles":["Event Design","Film/Video Production","Pre-visualization","Live Programing","Projection Mapping"],"tech":["Custom Live Video Mixer","CG Rendering and Compositing","VR Previsualization"],"content":"\n\n\n<p>\n    Luxloop was approached by Creacíon Events to create a unique installation for a 36-seat pop-up dinner during Art Basel Miami featuring food by Michelin Star chef Vicky Cheng and renowned pastry chef Andrés Lara.\n</p>\n\n<p>\n    Luxloop designed a dining environment with full-room projection to surround the diners and developed a series of short films inspired by Chef Vicky Chen’s menu, transporting the guests to another world based on the dish for each course. The projections were live cued throughout the dinner and responded in real time to the movements and interactions of the guests, staff, and performers within the space.\n</p>\n\n<p>\n    The films were created using a combination of studio photography, high-speed video capture, motion graphics, 2D and 3D animation to create truly unique and stunning environments.\n</p>\n\n<img src=\"/assets/projects/blackcloak/bc5.png\">\n\n<img src=\"/assets/projects/blackcloak/screen2.png\">\n<img src=\"/assets/projects/blackcloak/screen3.png\">\n<img src=\"/assets/projects/blackcloak/screen4.png\">\n\n<h1>Previsualization Workflow</h1>\n\n<p>\n    Working with non-traditional video formats, we knew we’d need to develop new tools to aid in our content creation process. Leading up to the event, we created a custom suite of previsualization tools to test-run our live video mixing workflow off-site and simulate the experience of the diner before we were able to arrive on site, including a VR app that allowed us to preview content at scale, before the space was even built out.\n</p>\n\n<p>\n    The films were cued, mixed and composited live using Touch Designer, which enabled us to account for and respond to changes in timing, guest and staff movements, as well as the music from a live DJ set. The final result was a seamless visual experience that led guests from one course to another.\n</p>\n\n<div class=\"fitVid\">\n  <iframe src=\"http://player.vimeo.com/video/198264860?title=0&amp;byline=0&amp;portrait=0&amp;color=ffffff\" width=\"720\" height=\"405\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n</div>\n\n<div class=\"fitVid\">\n  <iframe src=\"http://player.vimeo.com/video/198264992?title=0&amp;byline=0&amp;portrait=0&amp;color=ffffff\" width=\"720\" height=\"405\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n</div>\n\n<img src=\"/assets/projects/blackcloak/touch.png\">\n<img src=\"/assets/projects/blackcloak/vr.png\">\n\n\n"},{"name":"If the Walls Had Eyes","headline":"Interactive Video Installation","slug":"eyes","previewImg":"/assets/projects/eyes/1.jpg","aspectRatio":"3-4","priority":6,"coverImg":"/assets/projects/eyes/1.jpg","roles":["Concept Development","Content Production","Interactive Experience-Design"],"tech":["Spatial Sensing"],"team":[{"credit":"Creative Direction by","people":["Mandy Mandelstein"]},{"credit":"Software by by","people":["Ivaylo Getov","Mandy Mandelstein"]}],"links":[{"address":"http://bedfordandbowery.com/2015/11/the-walls-have-eyes-at-this-interactive-exhibit-where-tech-and-art-collide/","text":"Bedford + Bowery"},{"address":"http://blog.sixtyhotels.com/5-must-sees-select-art-fair/","text":"SELECT FAIR 2015"},{"address":"http://onenightstand-la.com/","text":"One Night Stand Los Angeles 2015"}],"content":"\n<p>\n  If The Walls Had Eyes visualizes and humanizes the multiple pairs of eyes that observe the things we putting out into the world on a daily basis, not only by the people we wish to see our personal content, but the digital eyes that are always watching, the ones we don't necessarily think about. Part inspired by an attention-starved roommate, and part by a dream, the interactive projection installation consists of multiple videos that watch and follow the viewer as they pass by.\n</p>\n\n<div class=\"fitVid\">\n  <iframe src=\"http://player.vimeo.com/video/113986453?title=0&amp;byline=0&amp;portrait=0&amp;color=ffffff\" width=\"720\" height=\"405\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n</div>\n\n<!-- <img src=\"/assets/projects/afteralifeahead/phar1.png\" class=\"caption captionLight captionRight captionIn\" data-caption=\"Photo: Ola Rindal\"> -->\n<img src=\"/assets/projects/eyes/gifSmall.gif\">\n<img src=\"/assets/projects/eyes/5.jpg\">\n<img src=\"/assets/projects/eyes/2.jpg\">\n"},{"name":"Overheard","headline":"Site-Specific Audio Narrative","slug":"overheard","previewImg":"/assets/img/oh.jpg","aspectRatio":"9-16","priority":1,"coverImg":"/assets/projects/overheard/appinhand.jpg","roles":["Concept Development","Content Production","Interactive Experience-Design"],"tech":["Native iOS App","Custom Web API","Bluetooth Beacons"],"links":[{"address":"http://www.nytimes.com/2016/10/30/arts/design/technology-invites-a-deep-dive-into-art.html?smid=fb-share&_r=1","text":"New York Times"},{"address":"http://www.3m.com/3M/en_US/Newsroom/Full-Story/?storyid=a38c9241-42d9-4608-9de4-e50d0db70480","text":"3M Newsroom"},{"address":"http://overheard.luxloop.com","text":"Project Page"}],"content":"\n<p>\n    As recipient of the inaugural 3M Art and Technology Prize at the Minneapolis Institute of Art, Luxloop was tasked with developing a new way that museum visitors could engage with the permanent collection.\n</p>\n\n<p class=\"bolder\">\n    Our primary goal was to create an experience that would add a layer on top of a visitor’s existing interaction with the museum instead of pulling focus away from the most important thing: the art.\n</p>\n\n<p>\n    By examining common social interactions in museums, we discovered a tendency for museum goers to listen-in to the conversations around them in the gallery spaces.  Building upon the familiar interaction of a museum audio guide, we decided to develop a custom audio-based augmented reality app that would allow visitors to explore this impulse to eavesdrop.\n</p>\n\n<p>\n    Similar to immersive theater plays such as <span class=\"italic\">Sleep no More</span> and <span class=\"italic\">Hopscotch</span>, Overheard lets users listen-in on the conversations of fictional characters that are embedded in specific sites throughout the museum, allowing users to explore stories in their own way, at their own pace.\n</p>\n\n<img src=\"/assets/projects/overheard/cover.png\">\n\n<div class=\"quote\">\n    Luxloop understood the museum experience through the eyes of the visitor. They wanted to create an audio-only experience so people could be in the museum with eyes up on the art while listening to something totally unique.\n    <span class=\"source\">Douglas Hegley, director of media and technology at Mia</span>\n</div>\n\n\n<h1>Combining Technology and Narrative</h1>\n<p>\n    We did extensive research on the demographics and motivations of Mia’s museum visitors so that we could create characters that were authentic to the context. We then worked with a screenwriter to craft the dialogue of five 15-minute-long narratives that would be embedded in the museum with <span class=\"bolder\">location-specific audio in 97 rooms, representing over 3000 years of art</span>.\n</p>\n\n<img src=\"/assets/projects/overheard/demo.gif\">\n<img src=\"/assets/projects/overheard/oh8.jpg\">\n\n<p>\n    We did extensive research on the demographics and motivations of Mia’s museum visitors so that we could create characters that were authentic to the context. We then worked with a screenwriter to craft the dialog of five 15-minute-long narratives that would be embedded in the museum with <span class=\"bolder\">location-specific audio in 97 rooms, representing over 3000 years of art</span>.\n</p>\n\n<p>\n    After considering several options for tracking users locations, we deployed a network of Bluetooth Low Energy beacons across the entire museum. We developed a custom algorithm for tracking user location based on the specific needs of Overheard that increased accuracy over 20% compared to existing solutions. Finally, working with the museum’s Media/Technology and Curatorial departments we created a custom content framework that could scale and change to accommodate the museum’s ongoing operations.\n</p>\n\n<p>\n    Overheard checks Mia’s collections database and local weather conditions in realtime, so <span class=\"bolder\">the app can dynamically change in response to individual works of art changing or moving, as well as specific weather conditions</span>. This way, the fictional characters are always reacting to and addressing the same real-life environment that the user is in.\n</p>\n\n<div class=\"quote\">\n    Design is about creating an engaging experience. That’s what was so great about Luxloop’s project – they blended technology, design and experiential thinking, and they didn’t get in the way of Mia’s exhibits. They enhance them.\n    <span class=\"source\">Collin Hummel - Sr. Brand Design Manager, 3M Design</span>\n</div>\n\n<img src=\"/assets/projects/overheard/oh2.jpg\">\n\n<p>\n    By organically incorporating site-specific narrative into an existing experience, <span class=\"bolder\">we created a new way for visitors to engage with and relate to both the art on view and the museum context as a whole</span>. Though fictional, the characters and their motives are relatable and provide a window into a variety of opinions and points of view, allowing visitors to validate and strengthen their own relationships with the museum.\n</p>\n\n\n\n"},{"name":"Pigments","headline":"Interactive Online Music Video","slug":"pigments","previewImg":"/assets/img/pigments.jpg","aspectRatio":"2-3","priority":3,"coverImg":"/assets/projects/pigments/cover.jpg","roles":["Interaction Design","Full-Stack Development"],"tech":["Node.js","Canvas","WebAudio API","Websockets"],"links":[{"address":"http://nerdist.com/las-elohim-shares-pigments-website-allows-users-to-control-her-heartbeat-premiere/","alt":"LA’s Elohim Shares “PIGMENTS” Website","text":"Nerdist"},{"address":"https://www.chromeexperiments.com/experiment/pigments","text":"Chrome Experiments"},{"address":"http://www.purplesneakers.com.au/2016/04/watch-elohims-pigments/","text":"Purple Sneakers"},{"address":"http://pigeonsandplanes.com/news/2016/04/check-out-elohims-interactive-new-video-for-pigments","text":"Pigeons and Planes"},{"address":"http://whitestone.io/project/pigments/","text":"Whitestone"}],"content":"\n<p>\n    <a href=\"http://icantmakeuloveu.com/\" class=\"linkAnim bolder\" target=\"_blank\">icantmakeuloveu.com</a>\n</p>\n\n<p>\n  LA-based artist Elohim approached Luxloop to create something more personal than a traditional music video.\n</p>\n\n<p>\n  Pigments is a multi-screen interactive experience that requires the viewer to help keep the video “alive.” Viewers use their mobile device to connect and control the experience within a desktop video browser, and are asked to provide the heartbeat of the song. If they successfully keep the video alive, the are rewarded with a multifaceted video that responds and changes based on their tactile input and creates a shareable, unique heartbeat graphic.\n</p>\n\n<p>\n  If the viewer stops tapping, the song slowly breaks apart and fades away, until the video ultimately dies.\n</p>\n\n<div class=\"fitVid\">\n  <iframe src=\"http://player.vimeo.com/video/198270687?title=0&amp;byline=0&amp;portrait=0&amp;color=ffffff\" width=\"720\" height=\"405\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n</div>\n\n<div class=\"quote\">\n    The project is an ingenious cross-platform concept that riffs on our growing obsession with virtual intelligence.\n    <span class=\"source\">Nerdist</span>\n</div>\n\n<h1>Building Connections</h1>\n<p>\n    Using node.js and socket.io, we built a custom websocket routing server to maintain pairs between a user’s phone and computer and handle their interaction input. Client-side WebGL and JavaScript dynamically build the experience for each user, react to their input, and generate the shareable graphics. The Webaudio API applies dynamic effects on multiple synced audio tracks to create the “dying” effect if users stop tapping out the heartbeat.\n</p>\n\n<img src=\"/assets/projects/pigments/download-1.png\">\n<img src=\"/assets/projects/pigments/pigments.gif\">\n<img src=\"/assets/projects/pigments/download-4.png\">\n\n<div class=\"quote\">\n    Focusing on this sense of emotion, the premise for Elohim’s interactive video clip for ‘Pigments’ is allowing you to control her heartbeat. It’s perhaps a little creepy, but also very beautiful.\n    <span class=\"source\">Pigeons and Planes</span>\n</div>\n\n<div class=\"fitVid\">\n  <iframe src=\"http://player.vimeo.com/video/198270480?title=0&amp;byline=0&amp;portrait=0&amp;color=ffffff\" width=\"720\" height=\"405\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n</div>\n"},{"name":"Social Sound","headline":"A Tool for Live Performance of the Social Sphere","slug":"socialsound","previewImg":"/assets/projects/socialsound/1.jpg","aspectRatio":"9-16","priority":4,"coverVid":{"vid":"/assets/projects/socialsound/socialsoundBg.mp4","poster":"/assets/projects/socialsound/vidThumb.jpg"},"showcaseImages":[{"image":"/assets/projects/socialsound/1.jpg","aspectRatio":"2-3","offset":-100},{"image":"/assets/projects/socialsound/2.jpg","aspectRatio":"2-3"},{"image":"/assets/projects/socialsound/3.jpg","aspectRatio":"2-3","offset":-200}],"showcaseVersion":2,"roles":["Concept Development","Content Production","Interactive Experience-Design"],"tech":["Node.js","Websockets","Twitter API"],"team":[{"credit":"Creative Direction and Software by","people":["Luxloop"]},{"credit":"\"#now\" performance video produced by","people":["Lauren Hoekstra","Doug Turner","Ivaylo Getov"]},{"credit":"Performers","people":["Christina Bobrowsky, Beck DeRobertis,","Lauren Hoekstra, Sean Keta, Dasha Kittredge,","Joshua Koopman, Taylor Laughlin, Moana Sherrill,","Amelia Steely, Jeremy Ungar, Nick Zeig-Owens"]}],"links":[{"address":"https://thecreatorsproject.vice.com/blog/social-sound-is-a-tool-for-turning-twitter-into-live-sound-art","text":"The Creators Project"},{"address":"http://prostheticknowledge.tumblr.com/post/125026527276/social-sound-creative-project-by-luxloop-is-tool","text":"Prosthetic Knowledge"}],"content":"\n\n<p>\n  Social Sound is a performance tool designed to aggregate the flow of real time social activity into a rush of sound in the real world, providing a unique portrait of the social sphere at a given moment in time.\n</p>\n\n<p>\n  A choir of people gather in one physical location, using the Social Sound website as their virtual songbook, ensuring that each performer is reading a unique part. Tweets containing the key search term are channelled to the performers, who narrate the thoughts out loud.\n</p>\n\n<p>\n  The tool defaults to tracking the word “now,” although any search term can be used. The tool can be found at socialsound.luxloop.com. If you use it to do something cool, let us know!\n</p>\n\n<div class=\"fitVid\">\n  <iframe src=\"http://player.vimeo.com/video/131315580?title=0&amp;byline=0&amp;portrait=0&amp;color=ffffff\" width=\"720\" height=\"405\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n</div>\n\n<img src=\"/assets/projects/socialsound/1.jpg\">\n<img src=\"/assets/projects/socialsound/2.jpg\">\n<img src=\"/assets/projects/socialsound/3.jpg\">\n"}]}